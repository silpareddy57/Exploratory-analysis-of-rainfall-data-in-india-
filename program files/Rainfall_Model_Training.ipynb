{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12a9d4e-0bac-4016-b065-ec3fb3f973e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af4ca4a-ce67-49eb-badb-5cebefec4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the Dataset\n",
    "# Ensure the filename matches exactly\n",
    "data = pd.read_csv('Weather.csv - Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78f411b-7a77-455a-9b9a-b3bd9755038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (145460, 24)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 24 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142207 non-null  object \n",
      " 23  @dropdown      0 non-null       float64\n",
      "dtypes: float64(17), object(7)\n",
      "memory usage: 26.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3. Initial Analysis\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f3cd63-8daa-4df4-a2c6-4388e28c3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handling Missing Values (Based on your project logic)\n",
    "# Drop columns with too many missing values as shown in your images\n",
    "data.drop(columns=['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ffa255-1298-4a6f-aa80-9f14b47aa9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical for cleaning\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2908b4d-ec79-4eac-b1b7-6019b0041c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric missing values with Mean - The New Way\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].fillna(data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcc9f28-f2df-4330-b8a8-162bc61318e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill categorical missing values with Most Frequent\n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_cols] = imp_mode.fit_transform(data[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbbcfbca-364d-4231-b094-240a77c2ee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "Date                  0\n",
      "Location              0\n",
      "MinTemp               0\n",
      "MaxTemp               0\n",
      "Rainfall              0\n",
      "WindGustDir           0\n",
      "WindGustSpeed         0\n",
      "WindDir9am            0\n",
      "WindDir3pm            0\n",
      "WindSpeed9am          0\n",
      "WindSpeed3pm          0\n",
      "Humidity9am           0\n",
      "Humidity3pm           0\n",
      "Pressure9am           0\n",
      "Pressure3pm           0\n",
      "Temp9am               0\n",
      "Temp3pm               0\n",
      "RainToday             0\n",
      "RainTomorrow          0\n",
      "@dropdown        145460\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values after cleaning:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ab74e1-bcc1-47b5-bde2-8084a31eee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete!\n",
      "Input Features (X) Shape: (145460, 20)\n",
      "   Location  MinTemp  MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
      "0        14     13.4     22.9       0.6           44.0          20.0   \n",
      "1        14      7.4     25.1       0.0           44.0           4.0   \n",
      "2        14     12.9     25.7       0.0           46.0          19.0   \n",
      "3        14      9.2     28.0       0.0           24.0          11.0   \n",
      "4        14     17.5     32.3       1.0           41.0           7.0   \n",
      "\n",
      "   WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Temp9am  \\\n",
      "0          24.0         71.0         22.0       1007.7       1007.1     16.9   \n",
      "1          22.0         44.0         25.0       1010.6       1007.8     17.2   \n",
      "2          26.0         38.0         30.0       1007.6       1008.7     21.0   \n",
      "3           9.0         45.0         16.0       1017.6       1012.8     18.1   \n",
      "4          20.0         82.0         33.0       1010.8       1006.0     17.8   \n",
      "\n",
      "   Temp3pm  RainToday  WindGustDir  WindDir9am  WindDir3pm  year  month  day  \n",
      "0     21.8          0           13          13          14  2008     12    1  \n",
      "1     24.3          0           14           6          15  2008     12    2  \n",
      "2     23.2          0           15          13          15  2008     12    3  \n",
      "3     26.5          0            4           9           0  2008     12    4  \n",
      "4     29.7          0           13           1           7  2008     12    5  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Feature Engineering: Convert 'Date' to Year, Month, and Day\n",
    "# This is crucial because your Flask app expects these 3 separate inputs\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['year'] = data['Date'].dt.year\n",
    "data['month'] = data['Date'].dt.month\n",
    "data['day'] = data['Date'].dt.day\n",
    "\n",
    "# Now we drop the original Date column and the '@dropdown' column if it exists\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "if '@dropdown' in data.columns:\n",
    "    data.drop(['@dropdown'], axis=1, inplace=True)\n",
    "\n",
    "# 2. Label Encoding: Convert words to numbers (e.g., 'Yes' -> 1, 'No' -> 0)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# List of columns that contain text/categories\n",
    "categorical_cols = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# 3. Define the features (X) and target (y)\n",
    "# We must arrange columns in the EXACT order the Flask app expects\n",
    "expected_columns = [\n",
    "    'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed',\n",
    "    'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
    "    'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
    "    'WindGustDir', 'WindDir9am', 'WindDir3pm', 'year', 'month', 'day'\n",
    "]\n",
    "\n",
    "X = data[expected_columns]\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "print(\"Encoding Complete!\")\n",
    "print(\"Input Features (X) Shape:\", X.shape)\n",
    "print(X.head()) # Look at the numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534cca70-51ce-45fa-a709-056929869e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model... Please wait, this might take a minute.\n",
      "Model Accuracy: 85.16%\n",
      "\n",
      "--- DONE! ---\n",
      "Check your folder. You should now see 'Rainfall.pkl' and 'scale.pkl'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# 1. Feature Scaling\n",
    "# This normalizes the data so the model treats all features fairly\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "# 2. Splitting the dataset into Train and Test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Training the Model (Random Forest)\n",
    "print(\"Training the model... Please wait, this might take a minute.\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# 4. Checking Accuracy\n",
    "y_pred = rf_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 5. SAVE THE FILES (The most important part!)\n",
    "# These files will appear in your folder. Your app.py needs them.\n",
    "pickle.dump(rf_model, open('Rainfall.pkl', 'wb'))\n",
    "pickle.dump(sc, open('scale.pkl', 'wb'))\n",
    "\n",
    "print(\"\\n--- DONE! ---\")\n",
    "print(\"Check your folder. You should now see 'Rainfall.pkl' and 'scale.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6404bdd-034c-46e4-b804-dbdea096f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
